%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% CSCI 1430 Written Question Template
%
% This is a LaTeX document. LaTeX is a markup language for producing documents. 
% You will fill out this document, compile it into a PDF document, then upload the PDF to Gradescope. 
%
% To compile into a PDF on department machines:
% > pdflatex thisfile.tex
%
% If you do not have LaTeX, your options are:
% - VSCode extension: https://marketplace.visualstudio.com/items?itemName=James-Yu.latex-workshop
% - Online Tool: https://www.overleaf.com/ - most LaTeX packages are pre-installed here (e.g., \usepackage{}).
% - Personal laptops (all common OS): http://www.latex-project.org/get/ 
%
% If you need help with LaTeX, please come to office hours.
% Or, there is plenty of help online:
% https://en.wikibooks.org/wiki/LaTeX
%
% Good luck!
% Srinath and the 1430 staff
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% How to include two graphics on the same line:
%
% \includegraphics[width=0.49\linewidth]{yourgraphic1.png}
% \includegraphics[width=0.49\linewidth]{yourgraphic2.png}
%
% How to include equations:
%
% \begin{equation}
% y = mx+c
% \end{equation}
%
% How to include code:
%
% \begin{python}
% def f(x):
%   return x
% \end{python}
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[11pt]{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[colorlinks = true,
            linkcolor = blue,
            urlcolor  = blue]{hyperref}
\usepackage[a4paper,margin=1.5in]{geometry}
\usepackage{stackengine,graphicx}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumerate}
\setlength{\headheight}{15pt}
\usepackage{microtype}
\usepackage{times}
\usepackage{booktabs}
\usepackage[shortlabels]{enumitem}
\setlist[enumerate]{topsep=0pt}
\usepackage{mdframed}

\usepackage{pythonhighlight}


\frenchspacing
\setlength{\parindent}{0cm} % Default is 15pt.
\setlength{\parskip}{0.3cm plus1mm minus1mm}

\pagestyle{fancy}
\fancyhf{}
\lhead{Homework 4 Questions}
\rhead{CSCI 1430}
% \lfoot{\textcolor{red}{Only 
% \ifcase\thepage
% \or instructions
% \or A1
% \or A1
% \or A2
% \or A2
% \or Q3
% \or A3
% \or A4
% \or A5
% \or Q6
% \or A6
% \or Q7
% \or A7
% \or feedback
% \else
% EXTRA PAGE ADDED
% \fi
% should be on this page
% }}
\rfoot{\thepage~/ 14}

\date{}

\title{\vspace{-2cm}Homework 4 Questions}


\begin{document}
\maketitle
\thispagestyle{fancy}
\vspace{-3cm}

\section*{Document Instructions}
\begin{itemize}
  \item 5 questions \textbf{[8 + 10 + 8 + 4 + 10 = 40 points]}.
  \item Fill all your answers within the answer boxes, and \textbf{please do NOT remove the answer box outlines}.
  \item Include code, images, and equations where appropriate.
  \item To identify all places where your responses are expected, search for `TODO'.
  \item Please make this document anonymous.
\end{itemize}

\section*{ Gradescope Instructions}
\begin{itemize}
  \item When you are finished, compile this document to a PDF and submit it directly to Gradescope. 
  \item You will be required to assign the appropriate answers to the right pages on Gradescope. \textbf{Failure to assign pages correctly will lead to a deduction of 2 points per misaligned page (capped at a maxmimum 6 point deduction).}
\end{itemize}
\pagebreak




% \paragraph{A2:} 

% a) Your answer here

% b) Your answer here

% c) Your answer here

 
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \pagebreak

% \textbf{Extra Space}

\pagebreak

\paragraph{Q1:} \textbf{[8 points]}

\begin{enumerate} [(a)]
    \item NEW: In machine learning, there are two main types of metric errors. These errors appear when the magnitude of the model's error is averaged over different testing/training data sets. Describe the main difference between these two types of errors.
    
    OLD: Describe these two types of machine learning.
    \begin{enumerate} [(i)]
    \item \textbf{[1 point]} Bias
    \begin{mdframed}
    TODO: Your answer to (a) (i) here.
    \end{mdframed}
    \item \textbf{[1 point]} Variance
    \begin{mdframed}
    TODO: Your answer to (a) (ii) here.
    \end{mdframed}
    \item \textbf{[2 points]} Why is it especially dangerous to confuse one for the other?
    \begin{mdframed}
    TODO: Your answer to (a) (iii) here.
    \end{mdframed}
    \end{enumerate}
    \item Define these terms in the context of evaluating a classifier:
    
    \begin{enumerate} [(i)]
    \item \textbf{[1 point]} Overfitting
    \begin{mdframed}
    TODO: Your answer to (b) (i) here.
    \end{mdframed}
    \item \textbf{[1 point]} Underfitting
    \begin{mdframed}
    TODO: Your answer to (b) (ii) here.
    \end{mdframed}
    \end{enumerate}
    \item \textbf{[2 points]} How do overfitting and underfitting relate to bias and variance?
    \begin{mdframed}
    TODO: Your answer to (c) here.
    \end{mdframed}
\end{enumerate}

% \emph{Please answer on the next page.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \pagebreak
% \paragraph{A3:} Your answer here.
% Uncomment the stencil below and fill in your solution.

% \begin{enumerate}[(a)]

% \item 
%     \begin{enumerate} [(i)]
%     \item 
%     \item
%     \end{enumerate}

% \item 
%     \begin{enumerate} [(i)]
%     \item 
%     \item
%     \end{enumerate}
% \item 

% \end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagebreak
\paragraph{Q2:} \textbf{[10 points]} Suppose we create a visual word dictionary using SIFT and k-means clustering for a scene recognition algorithm. 
\begin{enumerate}[(a)]
    \item \textbf{[4 points]} What characteristics would be desirable in the dataset that you choose to use to build your visual dictionary? Consider \href{https://www.telusinternational.com/articles/7-types-of-data-bias-in-machine-learning}{data bias trends} in popular machine learning datasets, the groups that these biases can harm, and how your choice in dataset could help. \textbf{[5-7 sentences]}

    \begin{mdframed}
    TODO: Your answer to (a) here.
    \end{mdframed}

    \item \textbf{[4 points]}
    After choosing an appropriate dataset, examination of the SIFT features generated from our training database tells us that many are almost equidistant from two or more visual words. 
    \begin{enumerate} [(i)]
    
    \item \textbf{[2 points]} Why might this affect classification accuracy?
    \begin{mdframed}
    TODO: Your answer to (i) here.
    \end{mdframed}
    
    \item \textbf{[2 points]} Why shouldn't we pick out a new dataset that better matches our model?
    \begin{mdframed}
    TODO: Your answer to (ii) here.
    \end{mdframed}
    \end{enumerate}
    

    \item \textbf{[2 points]}
    Given the situation, describe \emph{two} methods to improve classification accuracy, and explain why they would help.\\ 
    \emph{These can be for k-means, or otherwise.}
    
    \begin{mdframed}
    TODO: Your answer to (c) here.
    \end{mdframed}
    
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \paragraph{A4:} Your answer here.
% Uncomment the stencil below and fill in your solution.

% \begin{enumerate}[(a)]

% \item 

% \item 

% \end{enumerate}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagebreak
\paragraph{Q3:} \textbf{[8 points]} 
NEW: The bag of words representation handles the spatial layout of information in a way that can be an advantage or a disadvantage in different cases.

OLD: The way that the bag of words representation handles the spatial layout of visual information can be both an advantage and a disadvantage.
\begin{enumerate}[(a)]

\item \textbf{[5 point]} NEW: How might we determine whether bag of words is a good model? What are good metrics for evaluating the bag of words model's effectiveness? Discuss both technical and nontechnical benchmarks for a "good" model. \textbf{[5-6 sentences]}

OLD: How might we determine whether bag of words is a good model?
\begin{mdframed}
TODO: Your answer to (a) here.
\end{mdframed}

\item \textbf{[2 points]} 
NEW: Describe two example scenarios when dealing with visual information, one that illustrates an advantage of the bag of words representation, and another that shows a disadvantage of the bag of words representation.

OLD: Describe an example scenario for each of these cases.
\begin{mdframed}
TODO: Your answer to (b) here.
\end{mdframed}

\item \textbf{[1 point]} Describe a modification or additional algorithm which might overcome the disadvantage.
\begin{mdframed}
TODO: Your answer to (c) here.
\end{mdframed}


\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \paragraph{A5:} Your answer here.
% Uncomment the stencil below and fill in your solution.

% \begin{enumerate}[(a)]

% \item 

% \item 

% \item 

% \end{enumerate}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagebreak
\paragraph{Q4:} \textbf{[4 points]} Given a linear classifier such as SVM which separates two classes (binary decision), how might we use multiple linear classifiers to create a new classifier which separates $k$ classes?

Below, we provide pseudocode for a linear classifier. It trains a model on a training set, and then classifies a new test example into one of two classes. Please edit the pseudo-code to convert this into a multi-class classifier. 

\emph{Hints:} See slides in supervised learning crash course deck, plus your own research. You can take either the one vs.~all (or one vs.~others) approach or the one vs.~one approach in the slides; please declare which approach you take.

\emph{More hints:} Be aware that:
\begin{enumerate}
    \item The input labels in the multi-class case are different, and you will need to match the expected label input for the \texttt{train\_linear\_classifier} function
    \item You need to make a new decision on how to aggregate or decide on the most confident prediction
\end{enumerate}

\emph{Note:} A more efficient software application would separate the classifier training and testing into two different functions so that the model could be reused without retraining. Feel free to ignore this for now.

% \emph{Please answer on the next page.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \pagebreak
% \paragraph{A6:} Your answer here.
\begin{mdframed}
TODO: Select the implementation you chose.

\begin{tabular}[h]{lc}
\bottomrule
One vs One & $\square$ \\
One vs Many & $\square$ \\
\toprule
\end{tabular}
\end{mdframed}

\begin{python}
# Inputs
#   train_feats: N x d matrix of N features each d descriptor long
#   train_labels: N x 1 array containing values of either -1 
#               (class 0) or 1 (class 1)
#   test_feat: 1 x d image for which we wish to predict a label
#
#   Outputs: -1 (class 0) or 1 (class 1)
#
# Inputs:
#    As before, except
#    train_labels: N x 1 array of class label integers from 0 to k-1
# Outputs:
#    A class label integer from 0 to k-1
#

# TODO: Turn this into a multi-class classifier for k classes.
def classify(train_feats, train_labels, test_feat)
    # Train classification hyperplane
    weights, bias = train_linear_classifier(train_feats, train_label)
    # Compute distance from hyperplane
    test_score = weights * test_feats + bias

    return 1 if test_score > 0 else -1
\end{python}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak

\paragraph{Q5:} \textbf{[10 points]} In this homework, we will use a feature descriptor called HOG---`Histogram of Oriented Gradients'. As its name implies, it works similarly to SIFT. In classification, we might extract HOG features across the entire image (not just at interest points).

HOG creates one feature descriptor per image `block'. Each block is split into `cells' covering pixels. HOG outputs a 9-bin histogram of oriented gradients per cell. We append these together to obtain the feature descriptor for each block. As a result, if we have $(z,z)$ cells per block, the feature descriptor for each block will be of size $z \times z \times 9$. NEW: In other words, computing HOG over the whole image produces a matrix where each row is a descriptor. 
% On the other hand, a matrix might not useful in some cases. Thus, we might flatten the image as a vector. If we wish to extract a single feature vector per image, we would concatenate all block-level descriptors. (flattening in code --> vector)

\emph{Blocks can overlap as displayed in the diagram below.}

% \begin{center}
    \includegraphics[width=1.3\textwidth]{images/hog-diagram.png}
% \end{center}

\begin{enumerate}[(a)]
\item \textbf{[6 points]} Given a $72\times72$ image, calculate the number of cells, blocks, and final feature vector size that will occur when we extract HOG features over the whole image with the following parameters using maximum overlap between blocks.

\begin{enumerate}[(i)]
    \item \textbf{[3 $\times$ 1 points]}
Scenario 1: Pixels per cell = $4\times4$, cells per block = $4\times4$ % (\emph{like in SIFT!}). 

\begin{enumerate}[1.]
    \item 
Number of cells: 
\begin{mdframed}
TODO: Your answer to (a) (i) 1. here.
\end{mdframed}
    \item 
Number of blocks: 
\begin{mdframed}
TODO: Your answer to (a) (i) 2. here.
\end{mdframed}
    \item 
Dimensions of feature vector for the whole image: 
\begin{mdframed}
TODO: Your answer to (a) (i) 3. here.
\end{mdframed}
\end{enumerate}

\item \textbf{[3 $\times$ 1 points]}
Scenario 2: Pixels per cell = $8\times8$, cells per block = $2\times2$.
\begin{enumerate}[1.]
    \item 
Number of cells: 
\begin{mdframed}
TODO: Your answer to (a) (ii) 1. here.
\end{mdframed}
    \item 
Number of blocks: 
\begin{mdframed}
TODO: Your answer to (a) (ii) 2. here.
\end{mdframed}
    \item 
Dimensions of feature vector for the whole image: 
\begin{mdframed}
TODO: Your answer to (a) (ii) 3. here.
\end{mdframed}
\end{enumerate}
\end{enumerate}

\item \textbf{[2 + 2 points]}
When using HOG, the parameters such as pixels per cell and cells per block impact the resulting feature descriptor and so our performance on a classification task.

What are the pros and cons of the two parameter combinations? Which might you expect to have better performance?
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \pagebreak
% \paragraph{A7:} Your answer here.

% \emph{Note: You may find it interesting to read the thesis of Navneet Dalal (co-inventor of HOG) for more information on this topic. \href{http://lear.inrialpes.fr/people/dalal/NavneetDalalThesis.pdf}{[Link to thesis]} (pages 39, 41 in Section 4.3).}


% Uncomment the stencil below and fill in your solution.

% a)
% Scenario 1:
% \\ 
% Number of cells: 
% \\
% Number of blocks: 
% \\
% Dimensions of feature vector for the whole image: 
% \\


% Scenario 2:
% \\ 
% Number of cells: 
% \\
% Number of blocks: 
% \\
% Dimensions of feature vector for the whole image: 
% \\


% What are the pros and cons of the two parameter combinations? Which might you expect to have better performance?
% 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \pagebreak
% \paragraph{Secret something to think about:} Given a linear classifier like SVM, how might we handle data that are not linearly separable? How does the \emph{kernel trick} help in these cases? 

% \emph{Hint: See slides in supervised learning crash course deck, plus your own research.}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \paragraph{A:} Your answer here.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
\section*{Feedback? (Optional)}
Please help us make the course better. If you have any feedback for this assignment, we'd love to hear it!


% \pagebreak
% \section*{Any additional pages would go here.}


\end{document}
